from __future__ import annotations

from collections.abc import Iterable
from typing import (
    Annotated,
    Any,
    Literal,
    TypeAlias,
    cast,
)
import uuid

from openai.types.chat import (
    ChatCompletion,
    ChatCompletionMessage,
    ChatCompletionMessageParam,
    ChatCompletionToolParam,
)
from openai.types.chat.chat_completion import Choice as OpenaAIChoice
from openai.types.chat.chat_completion_content_part_image_param import (
    ChatCompletionContentPartImageParam,
)
from openai.types.chat.chat_completion_content_part_text_param import (
    ChatCompletionContentPartTextParam,
)
from openai.types.chat.chat_completion_message_tool_call import (
    ChatCompletionMessageToolCall,
    Function,
)
from openai.types.completion_usage import CompletionUsage as Usage
from pydantic import BaseModel, Field


ChatToolFunction: TypeAlias = Function

# ---------- Aliases from the OpenAI SDK ----------
ImageContent: TypeAlias = ChatCompletionContentPartImageParam
TextContent: TypeAlias = ChatCompletionContentPartTextParam
Message: TypeAlias = ChatCompletionMessageParam  # SDK union of message shapes

# Explicitly re-export OpenAI types that are part of our public API
__all__ = [
    "AMDAttestationToken",
    "AttestationReport",
    "ChatCompletion",
    "ChatCompletionMessage",
    "ChatCompletionMessageToolCall",
    "ChatRequest",
    "ChatToolFunction",
    "Choice",
    "Function",
    "HealthCheckResponse",
    "ImageContent",
    "Message",
    "MessageAdapter",
    "ModelEndpoint",
    "ModelMetadata",
    "NVAttestationToken",
    "ResultContent",
    "SearchResult",
    "SignedChatCompletion",
    "Source",
    "TextContent",
    "Topic",
    "TopicQuery",
    "TopicResponse",
    "Usage",
    "WebSearchContext",
    "WebSearchEnhancedMessages",
]


# ---------- Domain-specific objects for web search ----------
class ResultContent(BaseModel):
    text: str
    truncated: bool = False


class Choice(OpenaAIChoice):
    pass


class Source(BaseModel):
    source: str
    content: str


class SearchResult(BaseModel):
    title: str
    body: str
    url: str
    content: ResultContent | None = None

    def as_source(self) -> Source:
        text = self.content.text if self.content else self.body
        return Source(source=self.url, content=text)

    def model_post_init(self, __context) -> None:
        # Auto-derive structured fields when not provided
        if self.content is None and isinstance(self.body, str) and self.body:
            self.content = ResultContent(text=self.body)


class Topic(BaseModel):
    topic: str
    needs_search: bool = Field(..., alias="needs_search")


class TopicResponse(BaseModel):
    topics: list[Topic]


class TopicQuery(BaseModel):
    topic: str
    query: str


# ---------- Helpers ----------
def _extract_text_from_content(content: Any) -> str | None:
    """
    - If content is a str -> return it (stripped) if non-empty.
    - If content is a list of content parts -> concatenate 'text' parts.
    - Else -> None.
    """
    if isinstance(content, str):
        s = content.strip()
        return s or None
    if isinstance(content, list):
        parts: list[str] = []
        for part in content:
            if isinstance(part, dict) and part.get("type") == "text":
                t = part.get("text")
                if isinstance(t, str) and t.strip():
                    parts.append(t.strip())
        if parts:
            return "\n".join(parts)
    return None


# ---------- Adapter over the raw SDK message ----------
class MessageAdapter(BaseModel):
    """Thin wrapper around an OpenAI ChatCompletionMessageParam with convenience methods."""

    raw: Message

    @property
    def role(self) -> str:
        return cast("str", self.raw.get("role"))

    @role.setter
    def role(
        self,
        value: Literal["developer", "user", "system", "assistant", "tool", "function"],
    ) -> None:
        if not isinstance(value, str):
            raise TypeError("role must be a string")
        # Update the underlying SDK message dict
        # Cast to Any to bypass TypedDict restrictions
        cast("Any", self.raw)["role"] = value

    @property
    def content(self) -> Any:
        return self.raw.get("content")

    @content.setter
    def content(self, value: Any) -> None:
        # Update the underlying SDK message dict
        # Cast to Any to bypass TypedDict restrictions
        cast("Any", self.raw)["content"] = value

    @staticmethod
    def new_message(
        role: Literal["developer", "user", "system", "assistant", "tool", "function"],
        content: str | list[Any],
    ) -> Message:
        message: Message = cast("Message", {"role": role, "content": content})
        return message

    @staticmethod
    def new_tool_message(
        name: str,
        content: str,
        tool_call_id: str,
    ) -> Message:
        """Create a tool role message compatible with OpenAI SDK types.

        Example shape:
        {
          "role": "tool",
          "name": "execute_python",
          "content": "...",
          "tool_call_id": "call_abc123"
        }
        """
        message: Message = cast(
            "Message",
            {
                "role": "tool",
                "name": name,
                "content": content,
                "tool_call_id": tool_call_id,
            },
        )
        return message

    @staticmethod
    def new_assistant_tool_call_message(
        tool_calls: list[ChatCompletionMessageToolCall],
    ) -> Message:
        """Create an assistant message carrying tool_calls.

        Shape example:
        {
          "role": "assistant",
          "tool_calls": [...],
          "content": None,
        }
        """
        return cast(
            "Message",
            {
                "role": "assistant",
                "tool_calls": [tc.model_dump(exclude_unset=True) for tc in tool_calls],
                "content": None,
            },
        )

    @staticmethod
    def new_completion_message(content: str) -> ChatCompletionMessage:
        message: ChatCompletionMessage = cast(
            "ChatCompletionMessage", {"role": "assistant", "content": content}
        )
        return message

    def is_text_part(self) -> bool:
        return _extract_text_from_content(self.content) is not None

    def is_multimodal_part(self) -> bool:
        c = self.content
        if c is None:  # tool calling message
            return False
        if isinstance(c, str):
            return False

        for part in c:
            if isinstance(part, dict) and part.get("type") in (
                "image_url",
                "input_image",
            ):
                return True
        return False

    def extract_text(self) -> str | None:
        return _extract_text_from_content(self.content)

    def to_openai_param(self) -> Message:
        # Return the original dict for API calls.
        return self.raw


def adapt_messages(msgs: list[Message]) -> list[MessageAdapter]:
    return [MessageAdapter(raw=m) for m in msgs]


# ---------- Your additional containers ----------
class WebSearchEnhancedMessages(BaseModel):
    messages: list[Message]
    sources: list[Source]


class WebSearchContext(BaseModel):
    """Prompt and sources obtained from a web search."""

    prompt: str
    sources: list[Source]


# ---------- Request/response models ----------
class ChatRequest(BaseModel):
    model: str
    messages: list[Message] = Field(..., min_length=1)
    temperature: float | None = Field(default=None, ge=0.0, le=5.0)
    top_p: float | None = Field(default=None, ge=0.0, le=1.0)
    max_tokens: int | None = Field(default=None, ge=1, le=100000)
    stream: bool | None = False
    tools: Iterable[ChatCompletionToolParam] | None = None
    tool_choice: str | dict | None = "auto"
    nilrag: dict | None = {}
    web_search: bool | None = Field(
        default=False,
        description="Enable web search to enhance context with current information",
    )

    def model_post_init(self, __context) -> None:
        # Process messages after model initialization
        for i, msg in enumerate(self.messages):
            content = msg.get("content")
            if (
                content is not None
                and hasattr(content, "__iter__")
                and hasattr(content, "__next__")
            ):
                # Convert iterator to list in place
                cast("Any", msg)["content"] = list(content)

    @property
    def adapted_messages(self) -> list[MessageAdapter]:
        return adapt_messages(self.messages)

    def get_last_user_query(self) -> str | None:
        """
        Returns the latest non-empty user text (plain or from content parts),
        or None if not found.
        """
        for m in reversed(self.adapted_messages):
            if m.role == "user" and m.is_text_part():
                return m.extract_text()
        return None

    def has_multimodal_content(self) -> bool:
        """True if any message contains an image content part."""
        return any([m.is_multimodal_part() for m in self.adapted_messages])

    def ensure_system_content(self, system_content: str) -> None:
        """Ensure the conversation starts with a system message containing the given content.

        This method directly mutates the `self.messages` list in place.

        Logic cases:
        1. Empty message list: Insert new system message at the beginning
        2. First message is not system: Insert new system message at the beginning
        3. First message is system: Merge content with existing system message
           - String content: Append with separator
           - List content: Add new text part to the list
        """
        msgs = self.messages

        if not msgs:
            msgs.insert(0, MessageAdapter.new_message(role="system", content=system_content))
            return

        first_message = msgs[0]

        if first_message.get("role") != "system":
            msgs.insert(0, MessageAdapter.new_message(role="system", content=system_content))
            return

        existing_text = MessageAdapter(raw=first_message).extract_text() or ""
        content = first_message.get("content")

        if content is None or isinstance(content, str):
            first_message["content"] = (
                existing_text + ("\n\n" if existing_text else "") + system_content
            )
        elif isinstance(content, list):
            prefix = "\n\n" if existing_text else ""
            content.append({"type": "text", "text": prefix + system_content})


class SignedChatCompletion(ChatCompletion):
    signature: str
    sources: list[Source] | None = Field(
        default=None, description="Sources used for web search when enabled"
    )


class ModelMetadata(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    name: str
    version: str
    description: str
    author: str
    license: str
    source: str
    supported_features: list[str]
    tool_support: bool
    multimodal_support: bool = False


class ModelEndpoint(BaseModel):
    url: str
    metadata: ModelMetadata


class HealthCheckResponse(BaseModel):
    status: str
    uptime: str


# ---------- Attestation ----------

AMDAttestationToken = Annotated[
    str, Field(description="The attestation token from AMD's attestation service")
]

NVAttestationToken = Annotated[
    str, Field(description="The attestation token from NVIDIA's attestation service")
]


class AttestationReport(BaseModel):
    verifying_key: Annotated[str, Field(description="PEM encoded public key")]
    cpu_attestation: AMDAttestationToken
    gpu_attestation: NVAttestationToken
