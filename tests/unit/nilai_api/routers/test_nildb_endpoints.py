from unittest.mock import AsyncMock, MagicMock, patch

from fastapi import HTTPException, status
import pytest

from nilai_api.auth.common import AuthenticationInfo, PromptDocument
from nilai_api.db.users import RateLimits, UserData, UserModel
from nilai_api.handlers.nildb.api_model import (
    PromptDelegationToken,
)


class TestNilDBEndpoints:
    """Test class for nilDB-related API endpoints"""

    @pytest.fixture
    def mock_subscription_owner_user(self):
        """Mock user data for subscription owner"""
        mock_user_model = MagicMock(spec=UserModel)
        mock_user_model.user_id = "owner-id"
        mock_user_model.rate_limits = RateLimits().get_effective_limits().model_dump_json()
        mock_user_model.rate_limits_obj = RateLimits().get_effective_limits()

        return UserData.from_sqlalchemy(mock_user_model)

    @pytest.fixture
    def mock_regular_user(self):
        """Mock user data for regular user (not subscription owner)"""
        mock_user_model = MagicMock(spec=UserModel)
        mock_user_model.user_id = "user-id"
        mock_user_model.rate_limits = RateLimits().get_effective_limits().model_dump_json()
        mock_user_model.rate_limits_obj = RateLimits().get_effective_limits()

        return UserData.from_sqlalchemy(mock_user_model)

    @pytest.fixture
    def mock_auth_info_subscription_owner(self, mock_subscription_owner_user):
        """Mock AuthenticationInfo for subscription owner"""
        return AuthenticationInfo(
            user=mock_subscription_owner_user,
            token_rate_limit=None,
            prompt_document=None,
        )

    @pytest.fixture
    def mock_auth_info_regular_user(self, mock_regular_user):
        """Mock AuthenticationInfo for regular user"""
        return AuthenticationInfo(
            user=mock_regular_user, token_rate_limit=None, prompt_document=None
        )

    @pytest.fixture
    def mock_prompt_delegation_token(self):
        """Mock PromptDelegationToken"""
        return PromptDelegationToken(token="delegation_token_123", did="did:nil:builder123")

    @pytest.mark.asyncio
    async def test_get_prompt_store_delegation_success(
        self, mock_auth_info_subscription_owner, mock_prompt_delegation_token
    ):
        """Test successful delegation token request"""
        from nilai_api.routers.private import get_prompt_store_delegation

        with patch("nilai_api.routers.private.get_nildb_delegation_token") as mock_get_delegation:
            mock_get_delegation.return_value = mock_prompt_delegation_token

            request = "user-123"

            result = await get_prompt_store_delegation(request, mock_auth_info_subscription_owner)

            assert isinstance(result, PromptDelegationToken)
            assert result.token == "delegation_token_123"
            assert result.did == "did:nil:builder123"
            mock_get_delegation.assert_called_once_with("user-123")

    @pytest.mark.asyncio
    async def test_get_prompt_store_delegation_success_regular_user(
        self, mock_auth_info_regular_user, mock_prompt_delegation_token
    ):
        """Test delegation token request by regular user (endpoint no longer checks subscription ownership)"""
        from nilai_api.routers.private import get_prompt_store_delegation

        with patch("nilai_api.routers.private.get_nildb_delegation_token") as mock_get_delegation:
            mock_get_delegation.return_value = mock_prompt_delegation_token

            request = "user-123"

            result = await get_prompt_store_delegation(request, mock_auth_info_regular_user)

            assert isinstance(result, PromptDelegationToken)
            assert result.token == "delegation_token_123"

    @pytest.mark.asyncio
    async def test_get_prompt_store_delegation_handler_error(
        self, mock_auth_info_subscription_owner
    ):
        """Test delegation token request when handler raises an exception"""
        from nilai_api.routers.private import get_prompt_store_delegation

        with patch("nilai_api.routers.private.get_nildb_delegation_token") as mock_get_delegation:
            mock_get_delegation.side_effect = Exception("Handler failed")

            request = "user-123"

            with pytest.raises(HTTPException) as exc_info:
                await get_prompt_store_delegation(request, mock_auth_info_subscription_owner)

            assert exc_info.value.status_code == status.HTTP_500_INTERNAL_SERVER_ERROR
            assert "Server unable to produce delegation tokens: Handler failed" in str(
                exc_info.value.detail
            )

    @pytest.mark.asyncio
    async def test_chat_completion_with_prompt_document_injection(self):
        """Test chat completion with prompt document injection"""
        from nilai_api.routers.private import chat_completion
        from nilai_common import ChatRequest

        mock_prompt_document = PromptDocument(
            document_id="test-doc-123", owner_did="did:nil:" + "1" * 66
        )

        mock_user = MagicMock()
        mock_user.user_id = "test-user-id"
        mock_user.name = "Test User"
        mock_user.apikey = "test-api-key"
        mock_user.rate_limits = RateLimits().get_effective_limits()

        mock_auth_info = AuthenticationInfo(
            user=mock_user, token_rate_limit=None, prompt_document=mock_prompt_document
        )

        # Mock metering context
        mock_meter = MagicMock()
        mock_meter.set_response = MagicMock()

        # Mock log context
        mock_log_ctx = MagicMock()
        mock_log_ctx.set_user = MagicMock()
        mock_log_ctx.set_model = MagicMock()
        mock_log_ctx.set_request_params = MagicMock()
        mock_log_ctx.start_model_timing = MagicMock()
        mock_log_ctx.end_model_timing = MagicMock()

        request = ChatRequest(model="test-model", messages=[{"role": "user", "content": "Hello"}])

        with (
            patch("nilai_api.routers.private.get_prompt_from_nildb") as mock_get_prompt,
            patch("nilai_api.routers.private.AsyncOpenAI") as mock_openai_client,
            patch("nilai_api.routers.private.state.get_model") as mock_get_model,
            patch("nilai_api.routers.private.handle_nilrag") as mock_handle_nilrag,
            patch("nilai_api.routers.private.handle_web_search") as mock_handle_web_search,
        ):
            mock_get_prompt.return_value = "System prompt from nilDB"

            # Mock state.get_model() to return a ModelEndpoint
            mock_model_endpoint = MagicMock()
            mock_model_endpoint.url = "http://test-model-endpoint"
            mock_model_endpoint.metadata.tool_support = True
            mock_model_endpoint.metadata.multimodal_support = True
            mock_get_model.return_value = mock_model_endpoint

            # Mock handle_nilrag and handle_web_search
            mock_handle_nilrag.return_value = None
            mock_web_search_result = MagicMock()
            mock_web_search_result.messages = request.messages
            mock_web_search_result.sources = []
            mock_handle_web_search.return_value = mock_web_search_result

            # Mock OpenAI client
            mock_client_instance = MagicMock()
            mock_response = MagicMock()
            # Mock the response object that will be awaited
            mock_response.model_dump.return_value = {
                "id": "test-response-id",
                "object": "chat.completion",
                "created": 1234567890,
                "model": "test-model",
                "choices": [
                    {
                        "index": 0,
                        "message": {"role": "assistant", "content": "Test response"},
                        "finish_reason": "stop",
                    }
                ],
                "usage": {
                    "prompt_tokens": 10,
                    "completion_tokens": 5,
                    "total_tokens": 15,
                },
            }
            # Make the create method itself an AsyncMock that returns the response
            mock_client_instance.chat.completions.create = AsyncMock(return_value=mock_response)
            mock_client_instance.close = AsyncMock()
            mock_openai_client.return_value = mock_client_instance

            #
            # Call the function (this will test the prompt injection logic)
            # Note: We can't easily test the full endpoint without setting up the FastAPI app
            # But we can test that get_prompt_from_nildb is called
            try:
                await chat_completion(
                    req=request,
                    auth_info=mock_auth_info,
                    meter=mock_meter,
                    log_ctx=mock_log_ctx,
                )
            except Exception as e:
                # Expected to fail due to incomplete mocking, but we should still see the prompt call
                print("The exception is: ", str(e))
                raise e

            mock_get_prompt.assert_called_once_with(mock_prompt_document)

    @pytest.mark.asyncio
    async def test_chat_completion_prompt_document_extraction_error(self):
        """Test chat completion when prompt document extraction fails"""
        from nilai_api.routers.private import chat_completion
        from nilai_common import ChatRequest

        mock_prompt_document = PromptDocument(
            document_id="test-doc-123", owner_did="did:nil:" + "1" * 66
        )

        mock_user = MagicMock()
        mock_user.user_id = "test-user-id"
        mock_user.rate_limits = RateLimits().get_effective_limits()

        mock_auth_info = AuthenticationInfo(
            user=mock_user, token_rate_limit=None, prompt_document=mock_prompt_document
        )

        # Mock metering context
        mock_meter = MagicMock()
        mock_meter.set_response = MagicMock()

        # Mock log context
        mock_log_ctx = MagicMock()
        mock_log_ctx.set_user = MagicMock()
        mock_log_ctx.set_model = MagicMock()
        mock_log_ctx.set_request_params = MagicMock()

        request = ChatRequest(model="test-model", messages=[{"role": "user", "content": "Hello"}])

        with (
            patch("nilai_api.routers.private.get_prompt_from_nildb") as mock_get_prompt,
            patch("nilai_api.routers.private.state.get_model") as mock_get_model,
        ):
            # Mock state.get_model() to return a ModelEndpoint
            mock_model_endpoint = MagicMock()
            mock_model_endpoint.url = "http://test-model-endpoint"
            mock_model_endpoint.metadata.tool_support = True
            mock_model_endpoint.metadata.multimodal_support = True
            mock_get_model.return_value = mock_model_endpoint

            mock_get_prompt.side_effect = Exception("Unable to extract prompt")

            with pytest.raises(HTTPException) as exc_info:
                await chat_completion(
                    req=request,
                    auth_info=mock_auth_info,
                    meter=mock_meter,
                    log_ctx=mock_log_ctx,
                )

            assert exc_info.value.status_code == status.HTTP_403_FORBIDDEN
            assert "Unable to extract prompt from nilDB: Unable to extract prompt" in str(
                exc_info.value.detail
            )

    @pytest.mark.asyncio
    async def test_chat_completion_without_prompt_document(self):
        """Test chat completion when no prompt document is present"""
        from nilai_api.routers.private import chat_completion
        from nilai_common import ChatRequest

        mock_user = MagicMock()
        mock_user.user_id = "test-user-id"
        mock_user.rate_limits = RateLimits().get_effective_limits()

        mock_auth_info = AuthenticationInfo(
            user=mock_user,
            token_rate_limit=None,
            prompt_document=None,  # No prompt document
        )

        # Mock metering context
        mock_meter = MagicMock()
        mock_meter.set_response = MagicMock()

        # Mock log context
        mock_log_ctx = MagicMock()
        mock_log_ctx.set_user = MagicMock()
        mock_log_ctx.set_model = MagicMock()
        mock_log_ctx.set_request_params = MagicMock()
        mock_log_ctx.start_model_timing = MagicMock()
        mock_log_ctx.end_model_timing = MagicMock()

        request = ChatRequest(model="test-model", messages=[{"role": "user", "content": "Hello"}])

        with (
            patch("nilai_api.routers.private.get_prompt_from_nildb") as mock_get_prompt,
            patch("nilai_api.routers.private.AsyncOpenAI") as mock_openai_client,
            patch("nilai_api.routers.private.state.get_model") as mock_get_model,
            patch("nilai_api.routers.private.handle_nilrag") as mock_handle_nilrag,
            patch("nilai_api.routers.private.handle_web_search") as mock_handle_web_search,
        ):
            # Mock state.get_model() to return a ModelEndpoint
            mock_model_endpoint = MagicMock()
            mock_model_endpoint.url = "http://test-model-endpoint"
            mock_model_endpoint.metadata.tool_support = True
            mock_model_endpoint.metadata.multimodal_support = True
            mock_get_model.return_value = mock_model_endpoint

            # Mock handle_nilrag and handle_web_search
            mock_handle_nilrag.return_value = None
            mock_web_search_result = MagicMock()
            mock_web_search_result.messages = request.messages
            mock_web_search_result.sources = []
            mock_handle_web_search.return_value = mock_web_search_result

            # Mock OpenAI client
            mock_client_instance = MagicMock()
            mock_response = MagicMock()
            # Mock the response object that will be awaited
            mock_response.model_dump.return_value = {
                "id": "test-response-id",
                "object": "chat.completion",
                "created": 1234567890,
                "model": "test-model",
                "choices": [
                    {
                        "index": 0,
                        "message": {"role": "assistant", "content": "Test response"},
                        "finish_reason": "stop",
                    }
                ],
                "usage": {
                    "prompt_tokens": 10,
                    "completion_tokens": 5,
                    "total_tokens": 15,
                },
            }
            # Make the create method itself an AsyncMock that returns the response
            mock_client_instance.chat.completions.create = AsyncMock(return_value=mock_response)
            mock_client_instance.close = AsyncMock()
            mock_openai_client.return_value = mock_client_instance

            # Call the function
            try:
                await chat_completion(
                    req=request,
                    auth_info=mock_auth_info,
                    meter=mock_meter,
                    log_ctx=mock_log_ctx,
                )
            except Exception:
                # Expected to fail due to incomplete mocking
                pass

            # Should not call get_prompt_from_nildb when no prompt document
            mock_get_prompt.assert_not_called()

    def test_prompt_delegation_request_model_validation(self):
        """Test PromptDelegationRequest model validation"""
        # Valid request
        valid_request = "user-123"
        assert valid_request == "user-123"

        # Test with different types of user IDs
        request_with_uuid = "550e8400-e29b-41d4-a716-446655440000"
        assert request_with_uuid == "550e8400-e29b-41d4-a716-446655440000"

    def test_prompt_delegation_token_model_validation(self):
        """Test PromptDelegationToken model validation"""
        token = PromptDelegationToken(token="delegation_token_123", did="did:nil:builder123")
        assert token.token == "delegation_token_123"
        assert token.did == "did:nil:builder123"

    def test_user_data_structure(self, mock_subscription_owner_user, mock_regular_user):
        """Test the UserData structure has required fields"""
        # Check that UserData has the expected fields
        assert hasattr(mock_subscription_owner_user, "user_id")
        assert hasattr(mock_subscription_owner_user, "rate_limits")
        assert hasattr(mock_regular_user, "user_id")
        assert hasattr(mock_regular_user, "rate_limits")
